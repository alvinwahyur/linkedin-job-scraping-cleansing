{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Job Data Analyst in LinkedIn with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirement :\n",
    "- Python > 3.0 installed\n",
    "- Jupyter Notebook installed using PIP\n",
    "- Selenium installed using PIP\n",
    "- Pandas installed using PIP\n",
    "- Openpyxl installed using PIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Opening and scrolling job listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver\n",
    "browser = webdriver.Edge()\n",
    "\n",
    "#link url\n",
    "url_linkedin = \"https://www.linkedin.com/jobs/search/?keywords=data%20analyst&location=Indonesia\"\n",
    "\n",
    "#open browser\n",
    "browser.maximize_window()\n",
    "browser.get(url_linkedin)\n",
    "\n",
    "# Determine how many jobs we want to scrape, and calculate how many time we need to scroll down\n",
    "no_of_jobs = 1000\n",
    "n_scroll = int(no_of_jobs/25)+1\n",
    "print(n_scroll)\n",
    "i = 1\n",
    "browser.execute_script(\"return document.body.scrollHeight\") #scroll to top\n",
    "while i <= n_scroll:\n",
    "    browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    time.sleep(2) # wair for 2 seconds\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") #scroll to the bottom of page\n",
    "    time.sleep(3)\n",
    "    i = i + 1\n",
    "    try:\n",
    "        button = browser.find_element(By.XPATH,\"/html/body/div[1]/div/main/section[2]/button\")\n",
    "        #time.sleep(2)\n",
    "        button.click()\n",
    "        time.sleep(1)\n",
    "        print(\"Load More...\")\n",
    "    except:\n",
    "        browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        time.sleep(3)\n",
    "\n",
    "print(\"total jobs:\")        \n",
    "jobs = browser.find_element(By.CLASS_NAME,\"jobs-search__results-list\").find_elements(By.TAG_NAME,'li') # return a list\n",
    "print( len(jobs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get main attributes of each job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "company_name = []\n",
    "location = []\n",
    "date = []\n",
    "for job in jobs:\n",
    "    # title\n",
    "    job_title0 = job.find_element(By.CSS_SELECTOR,'h3').get_attribute('innerText')\n",
    "    job_title.append(job_title0)\n",
    "\n",
    "    # company\n",
    "    company_name0 = job.find_element(By.CSS_SELECTOR,'h4').get_attribute('innerText')\n",
    "    company_name.append(company_name0)\n",
    "\n",
    "\n",
    "    # location\n",
    "    location0 = job.find_element(By.CLASS_NAME,'job-search-card__location').get_attribute('innerText')\n",
    "    location.append(location0)\n",
    "\n",
    "    # date\n",
    "    date0 = job.find_element(By.CSS_SELECTOR,'div>div>time').get_attribute('datetime')\n",
    "    date.append(date0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = []\n",
    "seniority = []\n",
    "emp_type = []\n",
    "job_func = []\n",
    "industries = []\n",
    "for item in range(len(jobs)):\n",
    "    job_func0=[]\n",
    "    industries0=[]\n",
    "    # clicking job to view job details\n",
    "    try:\n",
    "        job_click_path = f'/html/body/div[1]/div/main/section[2]/ul/li[{item+1}]/div/a'\n",
    "        job_click = job.find_element(By.XPATH,job_click_path).click()\n",
    "    except:\n",
    "        job_click_path = f'/html/body/div[1]/div/main/section[2]/ul/li[{item+1}]/a/div/img'\n",
    "        \n",
    "    print(job_click_path)\n",
    "    job_click = job.find_element(By.XPATH,job_click_path).click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # job description\n",
    "    try:\n",
    "        jd_path = '/html/body/div[1]/div/section/div[2]/div/section[1]/div/div/section'\n",
    "        jd0 = job.find_element(By.XPATH,jd_path).get_attribute('innerText')\n",
    "    except:\n",
    "        jd_path = '/html/body/div[1]/div/section/div[2]/div/section[2]/div/div/section/div'\n",
    "        jd0 = job.find_element(By.XPATH,jd_path).get_attribute('innerText')    \n",
    "        is_benefit = True\n",
    "        \n",
    "    try:\n",
    "        assert 'Base pay range' in jd0\n",
    "    except:\n",
    "        is_benefit = False\n",
    "        \n",
    "    if is_benefit==True :\n",
    "        jd_path = '/html/body/div[1]/div/section/div[2]/div/section[2]/div/div/section/div'\n",
    "        jd0 = job.find_element(By.XPATH,jd_path).get_attribute('innerText')\n",
    "        jd.append(jd0)\n",
    "        jd_path2 = '/html/body/div[1]/div/section/div[2]/div/section[2]/div'\n",
    "    else:\n",
    "        jd.append(jd0)\n",
    "        jd_path2 = '/html/body/div[1]/div/section/div[2]/div/section[1]/div'\n",
    "    \n",
    "    # seniority\n",
    "    try:\n",
    "        seniority_path = jd_path2 + '/ul/li[1]/span'\n",
    "        seniority0 = job.find_element(By.XPATH,seniority_path).get_attribute('innerText')\n",
    "        seniority.append(seniority0)\n",
    "    except:\n",
    "        seniority.append('') #handling if seniority is not available\n",
    "    \n",
    "    # job employment\n",
    "    try:\n",
    "        emp_type_path = jd_path2 + '/ul/li[2]/span'\n",
    "        emp_type0 = job.find_element(By.XPATH,emp_type_path).get_attribute('innerText')\n",
    "        emp_type.append(emp_type0)\n",
    "    except:\n",
    "        emp_type.append('') #handling if employment type is not available\n",
    "    \n",
    "    # job function\n",
    "    try:\n",
    "        job_func_path = jd_path2 + '/ul/li[3]/span'\n",
    "        job_func0 = job.find_element(By.XPATH,job_func_path).get_attribute('innerText')\n",
    "        job_func.append(job_func0)\n",
    "    except:\n",
    "        job_func.append('') #handling if job function is not available\n",
    "    \n",
    "    # industry\n",
    "    try:\n",
    "        industries_path = jd_path2 + '/ul/li[4]/span'\n",
    "        industries0 = job.find_element(By.XPATH,industries_path).get_attribute('innerText')\n",
    "        industries.append(industries0)\n",
    "    except:\n",
    "        industries.append('') #handling if job industry is not available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Insert data to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data = pd.DataFrame({'Date': date,\n",
    "                        'Company': company_name,\n",
    "                        'Title': job_title,\n",
    "                        'Location': location,\n",
    "                        'Description' : jd,\n",
    "                        'Level': seniority,\n",
    "                        'Type': emp_type,\n",
    "                        'Function': job_func,\n",
    "                        'Industry': industries\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Export data to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = \"C:\\\\Users\\\\Alvin\\\\Documents\\\\Output\\\\DataScraping.xlsx\"\n",
    "job_data.to_excel(output_file_path, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PIP",
   "language": "python",
   "name": "pip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
